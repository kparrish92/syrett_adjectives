---
title: "Experiment 2: Word Learning - Single target frame"
format: html
editor: visual
---

```{r, include = FALSE}
library(here)
library(tidyverse)
library(janitor)
library(bayestestR)
library(bayesplot)
library(tidybayes)
library(modelr)
library(brms)

knitr::opts_chunk$set(echo = FALSE)

source(here::here("scripts", "task_2", "03_load_data.R"))
```

## Overview

Word Learning - Single target frame in a trial [task preview](https://idps.rutgers.edu/idp/profile/SAML2/Redirect/SSO?execution=e2s1)

Task: Participants were presented with a set of videos with a dialogue between two speakers featuring a novel word. At the end of each trial, they were asked to provide their guess about the novel word's meaning, and indicate their confidence level (scale: 1-4). The difference between this experiment and (1) is that in each target adjective trial, participants heard the adjective in predicative version and then only in ONE single other frame.

## Statistical Analysis

First, in order to determine the **probability of guessing an emotion adjective**, a Bayesian logistic regression was run. In the model, the fixed effect predictors were animacy condition (2 levels: animate, inanimate), frame condition (2 levels: bleached, lexical), and frame type (6 levels: "at DP because S", "about DP", "to VP", "that S", "about gerund", "of DP because S") and all interactions. Second, in order to analyze **confidence ratings**, an Bayesian ordinal regression was run. The outcome of this model was the probability of a confidence rating as a function of the same fixed effect predictors from the logistic model: animacy condition (2 levels: animate, inanimate) and frame condition (2 levels: bleached, lexical) and their interaction. All model priors were the default in `brms`, a student's T distribution with 3 degree of freedom. All models were fit with 4000 iterations (1000 warm-up). Hamiltonian Monte-Carlo sampling was carried out with 6 chains distributed between 6 processing cores.

## Results

Overall, the majority of guesses were classified as adjectives (`r round(total_adjective_guesses, digits = 2)*100`%). Of those, `r round(prop_emotional, digits = 2)*100`% were coded as emotion adjectives. The logistic model is summarized in @tbl-log-model (this can be included in the body of a paper or the appendix). The specific interpretation of the model output is discussed in the subsequent sections in more detail. I opted for short prose instead of style, for the sake of both clarity and brevity.

```{r}
#| label: tbl-log-model
#| tbl-cap: "Summary of the posterior distribution modeling of the probability of guessing an emotion adjective as a function of animacy and frame The table includes posterior medians, the 95% HDI, the percentage of the HDI within the ROPE, and the maximum probability of effect (MPE)."

read_csv(here("docs", "tables", "study_2_model.csv"), col_types = cols(.default = "c")) %>% 
  knitr::kable(format = "pandoc", align = c("l", "r", "r", "r", "r", "r"),
    label = "study2-mod-log")
```

### Did animacy matter?

Yes: emotion adjective guesses were highly probable in the animate (condition `r round(mean(a_df$.value), digits = 2)` HDI \[`r round(hdi(a_df$.value), digits = 2)[1]` -`r round(hdi(a_df$.value), digits = 2)[2]`\]). Guesses for inanimate adjectives were less likely to be emotion adjectives `r round(mean(ia_df$.value), digits = 2)` HDI \[`r round(hdi(ia_df$.value), digits = 2)[1]` -`r round(hdi(ia_df$.value), digits = 2)[2]`\].

### Did frame matter?

Not as much. Overall, the was less of a difference in frame (before we consider the interaction). That is, "overall" refers to the pooled estimates of a given frame of both animate and inanimate subjects. The probability of an emotion adjective in the lexical frame was `r round(mean(l_df$.value), digits = 2)` HDI \[`r round(hdi(l_df$.value), digits = 2)[1]` -`r round(hdi(l_df$.value), digits = 2)[2]`\]. The probability of an emotion adjective in the bleached frame was `r round(mean(b_df$.value), digits = 2)` HDI \[`r round(hdi(b_df$.value), digits = 2)[1]` -`r round(hdi(b_df$.value), digits = 2)[2]`\].

### What did the interaction of animacy and frame look like?

We do see clear differences in the interaction of animacy and frame. Specifically: The probability of an emotion adjective in the lexical frame with an inanimate subject was `r round(mean(il_df$.value), digits = 2)` HDI \[`r round(hdi(il_df$.value), digits = 2)[1]` -`r round(hdi(il_df$.value), digits = 2)[2]`\]. The probability of an emotion adjective in the bleached frame with an inanimate subject was `r round(mean(ib_df$.value), digits = 2)` HDI \[`r round(hdi(ib_df$.value), digits = 2)[1]` -`r round(hdi(ib_df$.value), digits = 2)[2]`\]. The probability of an emotion adjective in the lexical frame with an animate subject was `r round(mean(al_df$.value), digits = 2)` HDI \[`r round(hdi(al_df$.value), digits = 2)[1]` -`r round(hdi(al_df$.value), digits = 2)[2]`\]. Finally, the probability of an emotion adjective in the bleached frame with an animate subject was `r round(mean(ab_df$.value), digits = 2)` HDI \[`r round(hdi(ab_df$.value), digits = 2)[1]` -`r round(hdi(ab_df$.value), digits = 2)[2]`\].

We have a few options for plots here. Both plots below show the same information (the posterior distribution of the probability of guessing an emotion adjective), but present with a different fixed effect on the y-axis. In @fig-ani, animacy is on the y-axis. In this plot we can see that the probability of guessing an emotion adjective is very similar in the bleached and lexical frames when the subject is animate. On the other hand, lexical frame does make a difference when the subject is inanimate.

```{r}
#| label: fig-ani
#| fig-cap: "The probability of guessing an emotion adjective by animacy and frame"
knitr::include_graphics(here("docs", "plots", "task_2_bayesian.png"))
```

@fig-frame has the frame condition on the y-axis. This shows us that words with animate subjects are more likely to be guessed as emotion adjectives than ones with animate subjects in both lexical and bleached frames. These two plots are derived from the same model, but provide different insights. Depending on which one answers the research question better, we can include it.

```{r}
#| label: fig-frame
#| fig-cap: "The probability of guessing an emotion adjective by frame and animacy"
knitr::include_graphics(here("docs", "plots", "task_2_bayesian_frame.png"))
```

### Effect Sizes

Just as for some previous work, I included an two example effect size plots that plot the difference between the posterior distributions in @fig-ani. @fig-ani-es-1 shows all plausible differences in the effect of frame (going from bleached to lexical) in the inanimate condition. The number inside to distribution is the probability of the effect being positive (a 1 indicates that we are 100% sure the effect is positive based on our data). The numbers below the data points are the mean of the the distribution (or the most probable effect size), and the upper and lower bounds of the 95% Highest Density interval (HDI). @fig-ani-es-2 shows the same information in the animate condition. In this case, we see that the probability of positive effect is .39, suggesting that we are unsure of the direction of the effect. In other words, we can't conclude that frame made a difference when the subject was animate. On the other hand, we do see compelling evidence that frame is important when the subject is inanimate.

```{r}
#| label: fig-ani-es-1
#| fig-cap: "A distribution of plausible effect sizes going from bleached to lexical frames when the subject in inanimate"
knitr::include_graphics(here("docs", "plots", "inanimate_es.png"))
```

```{r}
#| label: fig-ani-es-2
#| fig-cap: "A distribution of plausible effect sizes going from bleached to lexical frames when the subject in animate"
knitr::include_graphics(here("docs", "plots", "animate_es.png"))
```

```{r}
#| layout-ncol: 2

knitr::include_graphics(here("docs", "plots", "inanimate_es.png"))
knitr::include_graphics(here("docs", "plots", "animate_es.png"))
```

### Ratings

Overall, subjects were not highly confident in their guesses. @fig-hist shows that 2 was chosen most often overall, where 4 was scarcely chosen at all. The ordinal model is summarized in @tbl-rating-mod, and the converted to probability and visualized in @fig-rat-mod

```{r}
#| label: fig-hist
#| fig-cap: "Histrograms of the confidence ratings in all 4 conditions"
knitr::include_graphics(here("docs", "plots", "ratings_desc.png"))
```

The ratings data show us that in three of the four possible cases, 2 was the most probable confidence rating. In the inanimate-bleached condition, 1 was the most probable confidence rating. Additionally, 4 was the least probable rating in all 4 conditions. However, in the animate-lexical condition, 3 was the second most probable rating, unlike the other three conditions, where 3 was the second-least probable rating. As a result, it is plausible that the participants were **most confident in their ratings in the animate-lexical condition.**

```{r}
#| label: tbl-rating-mod
#| tbl-cap: Summary of the posterior distribution modeling the probability of a given confidence rating as a function of animacy and frame The table includes posterior medians, the 95% HDI, the percentage of the HDI within the ROPE, and the maximum probabilityof effect (MPE)."

read_csv(here("docs", "tables", "study_2_model_ord.csv"), col_types = cols(.default = "c")) %>% 
  knitr::kable(format = "pandoc", align = c("l", "r", "r", "r", "r", "r"), 
    label = "study2-mod-ord")
```

```{r}
#| label: fig-rat-mod
#| fig-cap: "The posterior distribution of the ordinal model"
knitr::include_graphics(here("docs", "plots", "ratings_mod.png"))
```

#### Reporting table for ratings

I am including (adjusted) estimates derived from the model here, in which the each estimate represents the mean of the posterior distribution and is a probability. There should be reported with with estimate and 95% HDI, found in the following columns.

```{r}
#| tbl-cap: "Adjusted Estimates of the Ordinal Model"
ord_report %>% 
  dplyr::select(-X) %>% 
  knitr::kable(format = "pandoc")
```

### Within subjects Frame-type

@fig-ws-plot-mod shows the probability of guessing an emotion adjective in each of the 4 conditons for a 6 frame types. The shades of blue are animate conditions, while the red shades are inanimate conditions. Overall, animate conditions had a higher probability of being guessed as an emotion adjective than inanimate conditions.\
Additionally, in five out of seven cases, animate subjects in the lexical frame produced the highest probability of guessing an emotion adjective. In the remaining two ("to VP" and "about DP"), the animate-bleached condition was the condition in which an emotion adjective guess was the highest.

```{r}
#| label: fig-ws-plot-mod
#| fig-cap: "The probability of frame-type for each conditon"
knitr::include_graphics(here("docs", "plots", "ws_plot.png"))
```
